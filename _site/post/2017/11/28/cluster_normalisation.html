
<!-- Header bar -->

<!DOCTYPE html>
<html lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="author" content="">

<title>Feature Scaling for K-means</title>

<!-- Bootstrap Core CSS -->
<link href="http://localhost:4000/css/bootstrap.min.css" rel="stylesheet">

<!-- Custom CSS -->
<link href="http://localhost:4000/css/clean-blog.css" rel="stylesheet">

<!-- Custom Fonts -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
<link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

</head>

  <body>

  <!-- adjusting margin and border - not sure why it changed -->
<style>
.navbar {
  margin-bottom: 0;
  border-style: none;
}

</style>

<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://localhost:4000/index.html">Underwhelmed Ape</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
              <li ><a class="current" href="http://localhost:4000/index.html">Home</a></li>
              <li ><a href="http://localhost:4000/about.html">About Me</a></li>
              <!-- <li ><a href="http://localhost:4000/maker_projects.html">Making</a></li> -->
              <li ><a href="http://localhost:4000/all_posts.html">All Posts</a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


  <!-- Page Header -->
  <header class="intro-header" style="background-image: url('http://localhost:4000/img/post_images/cluster_normalisation/lights_background.jpeg')">
      <div class="container">
          <div class="row">
              <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                  <div class="site-heading">
                      <h1>Feature Scaling for K-means</h1>
                      <hr class="small">
                      
                      <span class="subheading"></span>
                      
                  </div>
              </div>
          </div>
      </div>
  </header>


    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">

                    <h1 id="introduction">Introduction</h1>

<p>This is a demonstration of the importance of normalising (also known as
standardising) data with distance based clustering techniques like
K-means. I was motivated by an answer in the Statistics StackExchange
community and have translated this from Python into R:
<a href="https://stats.stackexchange.com/questions/89809/is-it-important-to-scale-data-before-clustering">Cross-Validated</a>
translated into R.</p>

<p>There are several types of ‘cluster models’, each of which contain
several algorithms. These include Centroid, Hierarchical, distribution
and density based models. This post will focus on the most common
algorithm: K-means, the architypal centroid-model based algorithm.</p>

<p>For K-means, as a centroid based cluster model, each cluster is
represented by a single central mean vector (x,y) that minimises the sum
of squared residuals. As this seeks to minimise the Euclidian distance,
there are a number of assumptions that result from this:</p>

<ol>
  <li>Spherical Clusters
    <ul>
      <li>clusters must be separable such that the mean value (centroid)
converges to the cluster centre and clusters are not nested.</li>
    </ul>
  </li>
  <li>Similar scales
    <ul>
      <li>Clusters have similar variance</li>
    </ul>
  </li>
  <li>Similar sized clusters
    <ul>
      <li>Unbalanced sizes of clusters gives greater weighting to the
larger clusters.</li>
    </ul>
  </li>
</ol>

<p>The Euclidean distance is used here as I have continuous numerical
variables. In this example the two sets of data will on different scales
and will thus differ in their variances.</p>

<h2 id="packages">Packages</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(dplyr) # Data Manipulation
library(ggplot2) # Data Visualisation
library(ggExtra) # Adding marginal plots to ggplots
</code></pre></div></div>

<h1 id="simulating-the-data">Simulating the Data</h1>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Data along variable X to have single distribution with large range
x &lt;- rnorm(1000) * 10 + 50

# Data along Y to have two distributions with a smaller range
y &lt;- c(rnorm(500) + 10, rnorm(500) + 15)

# Binding the data together into a dataframe
df &lt;- as.data.frame(cbind(x,y))
head(df)

##          x         y
## 1 62.04969  9.818573
## 2 46.94655 10.573686
## 3 63.55241 10.463015
## 4 45.10800  9.276210
## 5 27.84014  8.870390
## 6 33.45776 11.068927
</code></pre></div></div>

<p>In this bi-variate example, the data along the x-axis is drawn from a
normal distribution and has a single modal value.</p>

<p>A bi-modal distribution was created on the y-axis; the data for each of
these distributions were drawn from different normal distributions,
creating a separation between clusters.</p>

<p>The range of the X-variable is larger than the range of Y.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ggExtra::ggMarginal(
    ggplot(df, aes(x = x, y = y)) +
        geom_point() + theme_bw(),
type = "histogram", fill = "lightgrey"
)
</code></pre></div></div>

<p><img src="/img/post_images/cluster_normalisation/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /></p>

<h1 id="data-analysis-and-results">Data Analysis and Results</h1>

<h2 id="k-means-on-un-scaled-data">K-means on un-scaled data</h2>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Perform K-means Clustering
km &lt;- kmeans(df, #features to be included in cluster model
             2, # number of clusters
             nstart = 20 # number of repeats
             )

#Create Dataframe of centroid locations
centroids &lt;- data.frame(Centroid = factor(seq(1:2)),
                        x = km$centers[,1],
                        y = km$centers[,2])

# Plot clusters on data with centroids
ggplot(df, aes(x = x, y = y)) +
    geom_point(aes(color = as.factor(km$cluster)), alpha = 0.5, pch = 19) +
    geom_point(data = centroids, aes(x = x, y = y, colour = Centroid), cex = 5, pch = 19) +
    guides(color = FALSE) + # remove legend
    theme_bw()
</code></pre></div></div>

<p><img src="/img/post_images/cluster_normalisation/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /></p>

<p>The algorithm has not clustered the data as we might have expected.
R-plots default to maximising the screen space and will distort each
axis for a better visualisation, and with the plot in this format it can
be difficult to see why the clusters have formed around these centroids.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ggplot(df, aes(x = x, y = y)) +
    geom_point(aes(color = as.factor(km$cluster)), pch = 19, alpha = 0.5) +
    geom_point(data = centroids, aes(x = x, y = y, colour = Centroid), cex = 5, pch = 19) +
    guides(color = FALSE) + # remove legend
    coord_fixed() + # maintain correct aspect ratio (assuming change in x is same as change in y)
    theme_bw()
</code></pre></div></div>

<p><img src="/img/post_images/cluster_normalisation/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /></p>

<p>This plot now maintains the aspect ratio, creating representative
distances between points.</p>

<p>K means iteratively optimises the clusters by minimising the Sum of
Squared Errors (SSE), i.e. the distances between the centroids and the
data points, similar to linear regression.</p>

<p>This assumes that the variance of each of the variables are the same.
With the large difference in the scales of each feature, this is not the
case:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>df %&gt;%
    summarise(range_x = max(x) - min(x),
              range_y = max(y) - min(y),
              var_x = var(x),
              var_y = var(y)) %&gt;%
    round(., 2) # round to 2 d.p.

##   range_x range_y var_x var_y
## 1   60.03   10.75 94.46  6.96
</code></pre></div></div>

<p>The data in this case are on different scales and thus more weighting is
given to the feature with the largest range.</p>

<h2 id="feature-normalisation">Feature normalisation</h2>

<p>Normilisation eliminates the problem of different scales by bringing all
values between 0 and 1. There are various ways to scale data, here I
have used Unity based normalisation.</p>

<script type="math/tex; mode=display">x\\prime = \\frac{x - min(x)}{max(x) - min(x)}</script>

<p>Where: <em>x</em> = data vector and <em>x</em>′ = normalised x</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Create Feature Scaling function that takes a numeric vector.
scaling &lt;- function(x){
    (x - min(x)) / (max(x) - min(x))
}

# new dataframe with scaled values
df %&gt;%
    dplyr::mutate(x_scaled = scaling(df$x),
                  y_scaled = scaling(df$y)) %&gt;%
    dplyr::select(x_scaled, y_scaled) -&gt; df_scaled

head(df_scaled)

##    x_scaled  y_scaled
## 1 0.7101954 0.2747678
## 2 0.4585957 0.3449835
## 3 0.7352288 0.3346926
## 4 0.4279676 0.2243350
## 5 0.1403063 0.1865991
## 6 0.2338890 0.3910346

ggplot(data = df_scaled,
       mapping = aes(x = x_scaled, y = y_scaled)
       ) +
    geom_point() +
    theme_bw()
</code></pre></div></div>

<p><img src="/img/post_images/cluster_normalisation/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /></p>

<h2 id="k-means-on-scaled-data">K-means on Scaled Data</h2>

<p>Now both features are on comparable scales, on which the Euclidean
distance can be measured to create a new K-means clustering model.</p>

<p>Results are plotted on the original scales for interpretability.</p>

<p>One issue with an iterative process such as k-means, is that the choice
of the initial starting point can influence the assignment of points to
clusters. The process is guaranteed to only find local optimums. This
can be accounted for by repeating the clustering mutiple times with
different randomly set initilisation values and choosing the result with
the lowest error rate. This is done using the <code class="highlighter-rouge">nstart = n</code> argument in
<code class="highlighter-rouge">kmeans()</code> function.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># run k-means on scaled data
km_scaled &lt;- kmeans(df_scaled, 2, nstart = 20)

# create an unscale function to return values back to original scale
unscale &lt;- function(x,y){
    x * ((max(y) - min(y))) + min(y)
}

centroids &lt;- data.frame(Centroid = factor(seq(1:2)),
                        x = unscale(km_scaled$centers[,1], df$x),
                        y = unscale(km_scaled$centers[,2], df$y))

ggplot(df, aes(x = x, y = y)) +
    geom_point(alpha = 0.5, pch = 19, aes(color = as.factor(km_scaled$cluster))) +
    geom_point(data = centroids, aes(x = x, y = y, colour = Centroid), cex = 5, pch = 19) +
    guides(color = FALSE) + # remove legend
    theme_bw()
</code></pre></div></div>

<p><img src="/img/post_images/cluster_normalisation/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /></p>

<p>The impact of feature scaling can be seen. this now satisfies the
assumptions of the Ordinary Least Squares, that minimises the sum of
squared errors, resulting in a more intuitive clustering.</p>

<h1 id="session-information">Session Information</h1>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sessionInfo()

## R version 3.4.2 (2017-09-28)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 16299)
##
## Matrix products: default
##
## locale:
## [1] LC_COLLATE=English_United Kingdom.1252
## [2] LC_CTYPE=English_United Kingdom.1252   
## [3] LC_MONETARY=English_United Kingdom.1252
## [4] LC_NUMERIC=C                           
## [5] LC_TIME=English_United Kingdom.1252    
##
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
##
## other attached packages:
## [1] bindrcpp_0.2       ggExtra_0.7        ggplot2_2.2.1.9000
## [4] dplyr_0.7.4       
##
## loaded via a namespace (and not attached):
##  [1] Rcpp_0.12.14     knitr_1.17       bindr_0.1        magrittr_1.5    
##  [5] munsell_0.4.3    xtable_1.8-2     colorspace_1.3-2 R6_2.2.2        
##  [9] rlang_0.1.4      plyr_1.8.4       stringr_1.2.0    tools_3.4.2     
## [13] grid_3.4.2       gtable_0.2.0     miniUI_0.1.1     htmltools_0.3.6
## [17] lazyeval_0.2.1   yaml_2.1.14      assertthat_0.2.0 rprojroot_1.2   
## [21] digest_0.6.12    tibble_1.3.4     shiny_1.0.5      mime_0.5        
## [25] glue_1.2.0       evaluate_0.10.1  rmarkdown_1.8    labeling_0.3    
## [29] stringi_1.1.6    compiler_3.4.2   scales_0.5.0     backports_1.1.1
## [33] httpuv_1.3.5     pkgconfig_2.0.1
</code></pre></div></div>


                    <div class="row">
                      <ul class="pager">
                        
                        <li class="previous"><a href="/post/2017/09/01/RIS.html">Older Posts</a></li>
                        

                        
                        <li class="next"><a href="">Newer Posts</a></li>
                        
                      </ul>
                    </div>

                </div>
            </div>
        </div>
    </article>

    <hr>

<!-- Footer -->

<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                  
                  <li>
                      <a href="https://github.com/underwhelmed-ape" target="_blank">
                          <span class="fa-stack fa-lg">
                              <i class="fa fa-circle fa-stack-2x"></i>
                              <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                          </span>
                      </a>
                  </li>
                  
                  
                  <li>
                      <a href="https://linkedin.com/in/james-ulyett-049a1238" target="_blank">
                          <span class="fa-stack fa-lg">
                              <i class="fa fa-circle fa-stack-2x"></i>
                              <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                          </span>
                      </a>
                  </li>
                  

                  <li>
                      <a href="https://www.youtube.com/watch?v=d5GecYjy9-Q" target="_blank">
                          <span class="fa-stack fa-lg">
                              <i class="fa fa-circle fa-stack-2x"></i>
                              <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                          </span>
                      </a>
                  </li>
                  <li>
                      <a href="https://www.youtube.com/watch?v=d5GecYjy9-Q" target="_blank">
                          <span class="fa-stack fa-lg">
                              <i class="fa fa-circle fa-stack-2x"></i>
                              <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                          </span>
                      </a>
                  </li>
                </ul>
                <p class="copyright text-muted">Copyright &copy; Infobesity 2018</p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="http://localhost:4000/js/jquery.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="http://localhost:4000/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="http://localhost:4000/js/clean-blog.min.js"></script>

</body>

</html>

